{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.5.2\n",
        "!pip install scikit-learn==1.5.2\n",
        "!pip install scikeras[tensorflow]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzrtvU5UETqf",
        "outputId": "632d0771-138e-4a99-9486-e13b332e62ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.5.2\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\n",
            "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.5.2\n",
            "Requirement already satisfied: scikit-learn==1.5.2 in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\n",
            "Collecting scikeras[tensorflow]\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras[tensorflow]) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras[tensorflow]) (1.5.2)\n",
            "Requirement already satisfied: tensorflow>=2.16.1 in /usr/local/lib/python3.11/dist-packages (from scikeras[tensorflow]) (2.18.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (3.6.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.16.1->scikeras[tensorflow]) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.16.1->scikeras[tensorflow]) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.16.1->scikeras[tensorflow]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.16.1->scikeras[tensorflow]) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras[tensorflow]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras[tensorflow]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras[tensorflow]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.16.1->scikeras[tensorflow]) (3.0.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold , train_test_split\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score , make_scorer, f1_score,precision_score, recall_score\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "YYWiFB5a20pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10)"
      ],
      "metadata": {
        "id": "k1gnZzedde65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_csv(\"/content/drive/MyDrive/ML/reg_features.csv\")\n",
        "y = pd.read_csv(\"/content/drive/MyDrive/ML/reg_labels.csv\")"
      ],
      "metadata": {
        "id": "ej66m6yw23hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_bgl(value):\n",
        "    if value < 140:\n",
        "        return 0\n",
        "    elif value <= 199:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "y['BGL'] = y['BGL'].apply(classify_bgl)"
      ],
      "metadata": {
        "id": "jvugsBws25Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y['BGL'],\n",
        "    test_size=0.2,\n",
        "    random_state=10,\n",
        "    stratify=y['BGL']\n",
        ")"
      ],
      "metadata": {
        "id": "v2ELbAOo26lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# convert scaled arrays back to DataFrames\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=10)\n",
        "X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "MHYhwogV28h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#boosting (with Gradient Boosting)"
      ],
      "metadata": {
        "id": "6416wJAG1phH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3heXQvqK1gUw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2cf17f49-2bb3-4619-b89a-38a774908f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Evaluation\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\\nprint(\"F1 Score:\", f1_score(y_test, y_pred_gb, average=\\'weighted\\'))\\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_gb))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import uniform\n",
        "\n",
        "\n",
        "# Gradient Boosting\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=10\n",
        ")\n",
        "\n",
        "\n",
        "# Hyperparameter space\n",
        "param_dist = {\n",
        "    'n_estimators': sp_randint(50, 300),\n",
        "    'learning_rate': uniform(0.01, 0.3),\n",
        "    'max_depth': sp_randint(2, 10),\n",
        "    'min_samples_split': sp_randint(2, 10),\n",
        "    'min_samples_leaf': sp_randint(1, 10),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'max_features': ['sqrt', 'log2',None] # Removed 'auto' as it is not a valid option\n",
        "}\n",
        "\n",
        "# Randomized Search\n",
        "random_search = RandomizedSearchCV(\n",
        "    gb_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,\n",
        "    scoring='f1_weighted',\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=10,\n",
        "    error_score='raise'\n",
        ")\n",
        "\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "best_gb_model = random_search.best_estimator_\n",
        "y_pred_gb = best_gb_model.predict(X_test_scaled)\n",
        "\n",
        "'''# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_gb, average='weighted'))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_gb))'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    # Predictions on training and test sets\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate on Training Data\n",
        "    print(\" Training Performance\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_train, y_train_pred, average='weighted'))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
        "\n",
        "    # Evaluate on Test Data\n",
        "    print(\" Test Performance\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_test_pred, average='weighted'))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "63vetOqs1-EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate_model(best_gb_model, X_train_scaled, y_train, X_test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrvOeW7dsfks",
        "outputId": "c5b0fa05-55ac-484a-eba6-f136d34b7f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training Performance\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       256\n",
            "           1       1.00      1.00      1.00       256\n",
            "           2       1.00      1.00      1.00       256\n",
            "\n",
            "    accuracy                           1.00       768\n",
            "   macro avg       1.00      1.00      1.00       768\n",
            "weighted avg       1.00      1.00      1.00       768\n",
            "\n",
            " Test Performance\n",
            "Accuracy: 0.8\n",
            "F1 Score: 0.8009597637504615\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90        65\n",
            "           1       0.68      0.71      0.70        21\n",
            "           2       0.58      0.58      0.58        19\n",
            "\n",
            "    accuracy                           0.80       105\n",
            "   macro avg       0.72      0.73      0.73       105\n",
            "weighted avg       0.80      0.80      0.80       105\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AdaBoost Classifier"
      ],
      "metadata": {
        "id": "UKUwemhk12V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from scipy.stats import randint, uniform\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grid for AdaBoost\n",
        "param_dist_ada = {\n",
        "    'n_estimators': np.arange(50, 300, 50),\n",
        "    'learning_rate': uniform(0.01, 1),\n",
        "    'estimator__max_depth': randint(2, 10),\n",
        "    'estimator__ccp_alpha': uniform(0.0, 0.1) # pruning parameter for DecisionTreeClassifier\n",
        "}\n",
        "\n",
        "# Create base estimator\n",
        "base_tree_tune = DecisionTreeClassifier(class_weight='balanced', random_state=10)\n",
        "\n",
        "# Create AdaBoost model for tuning\n",
        "ada_tune = AdaBoostClassifier(estimator=base_tree_tune, random_state=10)\n",
        "\n",
        "# Perform RandomizedSearchCV for AdaBoost\n",
        "random_search_ada = RandomizedSearchCV(\n",
        "    ada_tune,\n",
        "    param_distributions=param_dist_ada,\n",
        "    n_iter=30, # Increase n_iter for better exploration\n",
        "    cv=5,\n",
        "    scoring='f1_weighted', # Use f1_weighted as per previous models\n",
        "    n_jobs=-1,\n",
        "    random_state=10\n",
        ")\n",
        "\n",
        "random_search_ada.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search_ada.best_params_\n",
        "print(\"Best Params from RandomizedSearchCV:\", best_params)\n",
        "\n",
        "# Base estimator with pruning\n",
        "base_tree = DecisionTreeClassifier(\n",
        "    max_depth=best_params['estimator__max_depth'],\n",
        "    ccp_alpha=best_params['estimator__ccp_alpha'],\n",
        "    class_weight='balanced',\n",
        "    random_state=10\n",
        ")\n",
        "\n",
        "# AdaBoost model\n",
        "ada_model = AdaBoostClassifier(\n",
        "    estimator=base_tree,\n",
        "    n_estimators=best_params['n_estimators'],\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    random_state=10\n",
        ")\n",
        "\n",
        "'''#bagging\n",
        "bagged_boost_model = BaggingClassifier(\n",
        "    estimator=ada_model,\n",
        "    n_estimators=10,  # number of bagging iterations\n",
        "    random_state=10,\n",
        "    n_jobs=-1\n",
        ")'''\n",
        "\n",
        "# Step 3: Fit the model\n",
        "ada_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_test_pred = ada_model.predict(X_test_scaled)\n",
        "\n",
        "print(\" Final Evaluation on Test Set:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_test_pred, average='weighted'))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "gl6Vp-pS11rZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27060797-1608-492d-babe-ac61e4489fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params from RandomizedSearchCV: {'estimator__ccp_alpha': np.float64(0.014217004760152696), 'estimator__max_depth': 7, 'learning_rate': np.float64(0.5939013656536759), 'n_estimators': np.int64(100)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Final Evaluation on Test Set:\n",
            "Accuracy: 0.7904761904761904\n",
            "F1 Score: 0.7904991184205398\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90        65\n",
            "           1       0.60      0.71      0.65        21\n",
            "           2       0.62      0.53      0.57        19\n",
            "\n",
            "    accuracy                           0.79       105\n",
            "   macro avg       0.71      0.71      0.71       105\n",
            "weighted avg       0.79      0.79      0.79       105\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost\n",
        "\n"
      ],
      "metadata": {
        "id": "fLTjpr7Z2k9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "saRBQl6q2pnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5b296d-2e75-4e10-ace8-4478c93d90f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [2, 3, 4, 5, 6, 7, 8],  # limit tree depth\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
        "    'subsample': [0.6, 0.7, 0.8],\n",
        "    'colsample_bytree': [0.6, 0.7, 0.8],\n",
        "    'reg_alpha': [0, 0.01, 0.1, 1],   # L1 regularization\n",
        "    'reg_lambda': [0.1, 0.5, 1.0]        # L2 regularization\n",
        "}\n",
        "\n",
        "# Create XGBoost model\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "grid = RandomizedSearchCV(xgb_model, param_grid, cv=3, n_iter=30, scoring='f1_weighted', n_jobs=-1)\n",
        "\n",
        "# Fit model\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "\n",
        "# Predict\n",
        "y_val_pred = best_model.predict(X_test_scaled)\n",
        "y_train_pred = best_model.predict(X_train_scaled)"
      ],
      "metadata": {
        "id": "ccqZSk5a2sdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate_model(best_model, X_train_scaled, y_train, X_test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkpJr3yGmKh8",
        "outputId": "7a1043be-aa7d-4134-82be-f5afb3f1348d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training Performance\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       256\n",
            "           1       1.00      1.00      1.00       256\n",
            "           2       1.00      1.00      1.00       256\n",
            "\n",
            "    accuracy                           1.00       768\n",
            "   macro avg       1.00      1.00      1.00       768\n",
            "weighted avg       1.00      1.00      1.00       768\n",
            "\n",
            " Test Performance\n",
            "Accuracy: 0.819047619047619\n",
            "F1 Score: 0.813691537220949\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94        65\n",
            "           1       0.65      0.71      0.68        21\n",
            "           2       0.60      0.47      0.53        19\n",
            "\n",
            "    accuracy                           0.82       105\n",
            "   macro avg       0.73      0.71      0.72       105\n",
            "weighted avg       0.81      0.82      0.81       105\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#voting classification"
      ],
      "metadata": {
        "id": "koIBgejrCQGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##soft voting"
      ],
      "metadata": {
        "id": "faQSIzbBCWno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Create soft voting ensemble\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('gb', best_gb_model),\n",
        "        ('ada', ada_model),\n",
        "        ('xgb', best_model)\n",
        "    ],\n",
        "    voting='soft',\n",
        "    weights=[0.35, 0.25, 0.4],\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the voting classifier\n",
        "voting_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
        "y_train_pred_voting = voting_clf.predict(X_train_scaled)\n",
        "\n",
        "# Evaluation\n",
        "print(\" Voting Classifier Performance on Training Set:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred_voting))\n",
        "print(\"F1 Score:\", f1_score(y_train, y_train_pred_voting, average='weighted'))\n",
        "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred_voting))\n",
        "\n",
        "print(\" Voting Classifier Performance on Test Set:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_voting))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_voting, average='weighted'))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_voting))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AQW45r6epvX",
        "outputId": "616fb270-b765-479c-bea3-c36d6bb5f97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Voting Classifier Performance on Training Set:\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       256\n",
            "           1       1.00      1.00      1.00       256\n",
            "           2       1.00      1.00      1.00       256\n",
            "\n",
            "    accuracy                           1.00       768\n",
            "   macro avg       1.00      1.00      1.00       768\n",
            "weighted avg       1.00      1.00      1.00       768\n",
            "\n",
            " Voting Classifier Performance on Test Set:\n",
            "Accuracy: 0.8380952380952381\n",
            "F1 Score: 0.8337558181167205\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93        65\n",
            "           1       0.71      0.71      0.71        21\n",
            "           2       0.69      0.58      0.63        19\n",
            "\n",
            "    accuracy                           0.84       105\n",
            "   macro avg       0.77      0.75      0.76       105\n",
            "weighted avg       0.83      0.84      0.83       105\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hard Voting"
      ],
      "metadata": {
        "id": "_WI_qPG1C1nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Create hard voting ensemble\n",
        "hard_voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('gb', best_gb_model),\n",
        "        ('ada', ada_model),\n",
        "        ('xgb', best_model)\n",
        "    ],\n",
        "    voting='hard',\n",
        "    weights=[0.35, 0.25, 0.4],\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the hard voting classifier\n",
        "hard_voting_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_hard = hard_voting_clf.predict(X_test_scaled)\n",
        "y_train_pred_hard = hard_voting_clf.predict(X_train_scaled)\n",
        "\n",
        "# Evaluation\n",
        "print(\" Hard Voting Classifier Performance on Training Set:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred_hard))\n",
        "print(\"F1 Score:\", f1_score(y_train, y_train_pred_hard, average='weighted'))\n",
        "print(\"Classification Report:\\n\", classification_report(y_train, y_train_pred_hard))\n",
        "\n",
        "print(\" Hard Voting Classifier Performance on Test Set:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_hard, average='weighted'))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_hard))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lvblG97Cxqi",
        "outputId": "ba02d7df-e533-48d5-f531-7fcded93ebd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hard Voting Classifier Performance on Training Set:\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       256\n",
            "           1       1.00      1.00      1.00       256\n",
            "           2       1.00      1.00      1.00       256\n",
            "\n",
            "    accuracy                           1.00       768\n",
            "   macro avg       1.00      1.00      1.00       768\n",
            "weighted avg       1.00      1.00      1.00       768\n",
            "\n",
            " Hard Voting Classifier Performance on Test Set:\n",
            "Accuracy: 0.8095238095238095\n",
            "F1 Score: 0.8095272560388839\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.91      0.91        65\n",
            "           1       0.70      0.76      0.73        21\n",
            "           2       0.56      0.53      0.54        19\n",
            "\n",
            "    accuracy                           0.81       105\n",
            "   macro avg       0.72      0.73      0.73       105\n",
            "weighted avg       0.81      0.81      0.81       105\n",
            "\n"
          ]
        }
      ]
    }
  ]
}